{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anantapk03/farmer-rice-chatbot-model/blob/main/EvaluationRougeMeteorRevisi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clk4HCZnEONd"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets torch accelerate nltk rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt_7yFsIEVLl",
        "outputId": "44c4f804-d49a-4a77-bd70-88e058cc08ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import pandas as pd\n",
        "import math\n",
        "import tqdm\n",
        "import csv\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "\n",
        "# Pastikan punkt tokenizer NLTK sudah diunduh\n",
        "nltk.download('punkt')\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.add_special_tokens({\"pad_token\": \"<pad>\",\n",
        "                                \"bos_token\": \"<startofstring>\",\n",
        "                                \"eos_token\": \"<endofstring>\"})\n",
        "tokenizer.add_tokens([\"<bot>:\"])\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name) # Sesuaikan dengan tokenizer\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjCgTRF9EXmg",
        "outputId": "2bbb4a92-bf19-46c1-da4f-b3c8d9837919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tentukan path ke file model_state.pt yang sudah Anda simpan\n",
        "# Sesuaikan path ini dengan lokasi file Anda\n",
        "TOTAL_TRIAL_DATA = 10000 # Ganti dengan nilai yang sesuai jika berbeda\n",
        "TOTAL_EPOCH_TRIAL = 10 # Ganti dengan nilai yang sesuai jika berbeda\n",
        "model_path = \"/content/drive/MyDrive/POLINDRA/SKRIPSI/chatbot_trial_finetuning/Komodo7B/\"+str(TOTAL_TRIAL_DATA)+\"/EPOCH_\"+str(TOTAL_EPOCH_TRIAL)+\"/model_state.pt\"\n",
        "\n",
        "# Muat state dictionary model\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "# Set model ke mode evaluasi\n",
        "model.eval()\n",
        "\n",
        "print(\"Model state loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZksnInoKEZVi",
        "outputId": "76b16af0-3315-436c-f3b6-959cb07400d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model state loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisikan kembali kelas ChatData atau pastikan sudah tersedia di notebook ini\n",
        "class ChatData(Dataset):\n",
        "    def __init__(self, path: str, tokenizer, max_length: int = 150):\n",
        "        df = pd.read_csv(path)\n",
        "        df.dropna(subset=['pertanyaan', 'jawaban'], inplace=True)\n",
        "        df.drop_duplicates(subset=['pertanyaan', 'jawaban'], inplace=True)\n",
        "\n",
        "        self.X = [\n",
        "            f\"<startofstring> {row['pertanyaan']} <bot>: {row['jawaban']} <endofstring>\"\n",
        "            for _, row in df.iterrows()\n",
        "        ]\n",
        "\n",
        "        self.X_encoded = tokenizer(\n",
        "            self.X,\n",
        "            max_length=max_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        self.input_ids = self.X_encoded['input_ids']\n",
        "        self.attention_mask = self.X_encoded['attention_mask']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attention_mask[idx]\n",
        "\n",
        "# Tentukan path ke file test.csv\n",
        "# Sesuaikan path ini dengan lokasi file Anda\n",
        "test_data_path = \"/content/drive/MyDrive/POLINDRA/SKRIPSI/chatbot_trial_finetuning/Komodo7B/\"+str(TOTAL_TRIAL_DATA)+\"/DATASET/test.csv\"\n",
        "\n",
        "# Muat data test\n",
        "test_data = ChatData(test_data_path, tokenizer)\n",
        "test_loader = DataLoader(test_data, batch_size=32) # Sesuaikan batch size jika perlu\n",
        "\n",
        "print(\"Test data loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_urBO3cTEbcD",
        "outputId": "13af1a47-546b-425d-c160-66befaf7e40d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3cf7f61",
        "outputId": "a3de6ea0-3c69-4ff0-ea27-dff5dbcd3e9c"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4679af86",
        "outputId": "9f2312da-751c-4076-d337-c16e047560ea"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def compute_rouge_meteor(preds, refs):\n",
        "#     \"\"\"\n",
        "#     Menghitung skor ROUGE dan METEOR.\n",
        "\n",
        "#     Args:\n",
        "#         preds (list): List teks hipotesis (output model).\n",
        "#         refs (list): List teks referensi (jawaban sebenarnya).\n",
        "\n",
        "#     Returns:\n",
        "#         dict: Dictionary berisi skor ROUGE (rouge1, rouge2, rougel - precision, recall, fmeasure) dan METEOR.\n",
        "#     \"\"\"\n",
        "#     scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "#     rouge_scores = {'rouge1': {'precision': [], 'recall': [], 'fmeasure': []},\n",
        "#                     'rouge2': {'precision': [], 'recall': [], 'fmeasure': []},\n",
        "#                     'rougeL': {'precision': [], 'recall': [], 'fmeasure': []}}\n",
        "#     meteor_scores = []\n",
        "\n",
        "#     # Pastikan panjang preds dan refs sama\n",
        "#     if len(preds) != len(refs):\n",
        "#         print(\"Warning: Panjang prediksi dan referensi tidak sama.\")\n",
        "#         min_len = min(len(preds), len(refs))\n",
        "#         preds = preds[:min_len]\n",
        "#         refs = refs[:min_len]\n",
        "\n",
        "\n",
        "#     for pred, ref in zip(preds, refs):\n",
        "#         # ROUGE Score\n",
        "#         # Pastikan referensi dan prediksi tidak kosong sebelum menghitung skor\n",
        "#         if ref and pred:\n",
        "#             try:\n",
        "#                 scores = scorer.score(ref, pred) # Referensi sebagai argumen pertama\n",
        "#                 for metric in ['rouge1', 'rouge2', 'rougeL']:\n",
        "#                     rouge_scores[metric]['precision'].append(scores[metric].precision)\n",
        "#                     rouge_scores[metric]['recall'].append(scores[metric].recall)\n",
        "#                     rouge_scores[metric]['fmeasure'].append(scores[metric].fmeasure)\n",
        "#             except Exception as e:\n",
        "#                 print(f\"Error calculating ROUGE for ref: '{ref}', pred: '{pred}' - {e}\")\n",
        "\n",
        "\n",
        "#         # METEOR Score\n",
        "#         # Tokenisasi untuk METEOR\n",
        "#         ref_tokens = word_tokenize(ref)\n",
        "#         pred_tokens = word_tokenize(pred)\n",
        "#         # Pastikan token tidak kosong sebelum menghitung skor METEOR\n",
        "#         if ref_tokens and pred_tokens:\n",
        "#              try:\n",
        "#                 meteor_scores.append(meteor_score([ref_tokens], pred_tokens)) # Referensi sebagai list of lists\n",
        "#              except Exception as e:\n",
        "#                 print(f\"Error calculating METEOR for ref: '{ref}', pred: '{pred}' - {e}\")\n",
        "\n",
        "\n",
        "#     # Hitung rata-rata skor\n",
        "#     avg_rouge_scores = {}\n",
        "#     for metric in ['rouge1', 'rouge2', 'rougeL']:\n",
        "#         avg_rouge_scores[metric] = {}\n",
        "#         for score_type in ['precision', 'recall', 'fmeasure']:\n",
        "#             if rouge_scores[metric][score_type]:\n",
        "#                 avg_rouge_scores[metric][score_type] = sum(rouge_scores[metric][score_type]) / len(rouge_scores[metric][score_type])\n",
        "#             else:\n",
        "#                 avg_rouge_scores[metric][score_type] = 0.0\n",
        "\n",
        "\n",
        "#     if meteor_scores:\n",
        "#         avg_meteor_score = sum(meteor_scores) / len(meteor_scores)\n",
        "#     else:\n",
        "#         avg_meteor_score = 0.0\n",
        "\n",
        "\n",
        "#     return {\"rouge\": avg_rouge_scores, \"meteor\": avg_meteor_score}"
      ],
      "metadata": {
        "id": "W208XhldEdio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_rouge_meteor(preds, refs):\n",
        "    \"\"\"\n",
        "    Menghitung skor ROUGE dan METEOR berdasarkan prediksi dan referensi teks.\n",
        "    \"\"\"\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    rouge_scores = {'rouge1': {'precision': [], 'recall': [], 'fmeasure': []},\n",
        "                    'rouge2': {'precision': [], 'recall': [], 'fmeasure': []},\n",
        "                    'rougeL': {'precision': [], 'recall': [], 'fmeasure': []}}\n",
        "    meteor_scores = []\n",
        "\n",
        "    if len(preds) != len(refs):\n",
        "        print(\"‚ö†Ô∏è Warning: Panjang prediksi dan referensi tidak sama.\")\n",
        "        min_len = min(len(preds), len(refs))\n",
        "        preds = preds[:min_len]\n",
        "        refs = refs[:min_len]\n",
        "\n",
        "    for pred, ref in zip(preds, refs):\n",
        "        try:\n",
        "            # Hitung ROUGE\n",
        "            scores = scorer.score(ref, pred)\n",
        "            for metric in ['rouge1', 'rouge2', 'rougeL']:\n",
        "                rouge_scores[metric]['precision'].append(scores[metric].precision)\n",
        "                rouge_scores[metric]['recall'].append(scores[metric].recall)\n",
        "                rouge_scores[metric]['fmeasure'].append(scores[metric].fmeasure)\n",
        "        except Exception as e:\n",
        "            print(f\"[ROUGE Error] Ref: {ref} | Pred: {pred} | Err: {e}\")\n",
        "\n",
        "        try:\n",
        "            ref_tokens = word_tokenize(ref)\n",
        "            pred_tokens = word_tokenize(pred)\n",
        "            if ref_tokens and pred_tokens:\n",
        "                meteor_scores.append(meteor_score([ref_tokens], pred_tokens))\n",
        "        except Exception as e:\n",
        "            print(f\"[METEOR Error] Ref: {ref} | Pred: {pred} | Err: {e}\")\n",
        "\n",
        "    avg_rouge_scores = {}\n",
        "    for metric in rouge_scores:\n",
        "        avg_rouge_scores[metric] = {\n",
        "            score_type: (\n",
        "                sum(rouge_scores[metric][score_type]) / len(rouge_scores[metric][score_type])\n",
        "                if rouge_scores[metric][score_type] else 0.0\n",
        "            )\n",
        "            for score_type in ['precision', 'recall', 'fmeasure']\n",
        "        }\n",
        "\n",
        "    avg_meteor_score = sum(meteor_scores) / len(meteor_scores) if meteor_scores else 0.0\n",
        "\n",
        "    return {'rouge': avg_rouge_scores, 'meteor': avg_meteor_score}"
      ],
      "metadata": {
        "id": "DD10jLGmFfeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_references = []\n",
        "# test_hypotheses = []\n",
        "\n",
        "# print(\"Generating predictions for test set...\")\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     for X, a in tqdm.tqdm(test_loader, desc=\"Evaluating\"): # Gunakan tqdm untuk progress bar\n",
        "#         X, a = X.to(device), a.to(device)\n",
        "\n",
        "#         # Generate predictions\n",
        "#         # Sesuaikan parameter generate seperti max_new_tokens sesuai kebutuhan\n",
        "#         generated = model.generate(\n",
        "#             X,\n",
        "#             attention_mask=a,\n",
        "#             max_new_tokens=150, # Sesuaikan dengan kebutuhan\n",
        "#             eos_token_id=tokenizer.eos_token_id,\n",
        "#             pad_token_id=tokenizer.pad_token_id # Tambahkan pad_token_id\n",
        "#             )\n",
        "\n",
        "#         # Decode predictions and references\n",
        "#         # Hapus token khusus saat decoding untuk evaluasi\n",
        "#         decoded_preds = [tokenizer.decode(g, skip_special_tokens=True) for g in generated]\n",
        "#         decoded_refs = [tokenizer.decode(x, skip_special_tokens=True) for x in X]\n",
        "\n",
        "\n",
        "#         test_hypotheses.extend(decoded_preds)\n",
        "#         test_references.extend(decoded_refs)\n",
        "\n",
        "\n",
        "# print(\"Calculating ROUGE and METEOR scores...\")\n",
        "\n",
        "# # Hitung skor ROUGE dan METEOR\n",
        "# evaluation_results = compute_rouge_meteor(test_hypotheses, test_references)\n",
        "\n",
        "# # Tampilkan hasilnya\n",
        "# print(\"\\nHasil Evaluasi ROUGE dan METEOR pada Test Set:\")\n",
        "# print(f\"ROUGE Scores: {evaluation_results['rouge']}\")\n",
        "# print(f\"METEOR Score: {evaluation_results['meteor']:.4f}\")"
      ],
      "metadata": {
        "id": "df-1llONEfnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_answers = []\n",
        "pred_answers = []\n",
        "\n",
        "print(\"üîç Generating predictions for test set...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X, a in tqdm.tqdm(test_loader, desc=\"Evaluating\"):\n",
        "        X, a = X.to(device), a.to(device)\n",
        "\n",
        "        # Decode input untuk mengambil hanya prompt (pertanyaan + \"<bot>:\")\n",
        "        prompts = []\n",
        "        for x in X:\n",
        "            decoded = tokenizer.decode(x, skip_special_tokens=False)\n",
        "            if \"<bot>:\" in decoded:\n",
        "                prompt = decoded.split(\"<bot>:\")[0] + \"<bot>:\"\n",
        "                prompts.append(prompt)\n",
        "            else:\n",
        "                prompts.append(decoded)\n",
        "\n",
        "        prompt_inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "\n",
        "        # Generate output dari prompt\n",
        "        generated = model.generate(\n",
        "            prompt_inputs['input_ids'],\n",
        "            attention_mask=prompt_inputs['attention_mask'],\n",
        "            max_new_tokens=150,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            pad_token_id=tokenizer.pad_token_id\n",
        "        )\n",
        "\n",
        "        # Decode prediksi\n",
        "        decoded_preds = tokenizer.batch_decode(generated, skip_special_tokens=False)\n",
        "\n",
        "        # Ekstrak bagian <bot>: ... <endofstring> dari hasil prediksi\n",
        "        for text in decoded_preds:\n",
        "            start = text.find(\"<bot>:\")\n",
        "            end = text.find(\"<endofstring>\")\n",
        "            answer = text[start + len(\"<bot>:\"):end if end != -1 else None].strip() if start != -1 else \"\"\n",
        "            pred_answers.append(answer)\n",
        "\n",
        "        # Ekstrak jawaban referensi dari input X\n",
        "        for x in X:\n",
        "            decoded = tokenizer.decode(x, skip_special_tokens=False)\n",
        "            start = decoded.find(\"<bot>:\")\n",
        "            end = decoded.find(\"<endofstring>\")\n",
        "            answer = decoded[start + len(\"<bot>:\"):end if end != -1 else None].strip() if start != -1 else \"\"\n",
        "            true_answers.append(answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FGadB4fFlHi",
        "outputId": "60a0c803-e9b0-4713-c5ab-a022a641b42a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Generating predictions for test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [04:11<00:00,  7.86s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import datetime\n",
        "\n",
        "# # Tentukan path untuk menyimpan hasil evaluasi ROUGE dan METEOR\n",
        "# # Tambahkan timestamp pada nama file\n",
        "# timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "# rouge_meteor_log_path = \"/content/drive/MyDrive/POLINDRA/SKRIPSI/chatbot_trial_finetuning/Komodo7B/\"+str(TOTAL_TRIAL_DATA)+\"/EPOCH_\"+str(TOTAL_EPOCH_TRIAL)+f\"/rouge_meteor_evaluation_log_{timestamp}.csv\"\n",
        "\n",
        "# # Buka file CSV dalam mode 'write' ('w')\n",
        "# with open(rouge_meteor_log_path, \"w\", newline='') as f:\n",
        "#     writer = csv.writer(f)\n",
        "\n",
        "#     # Tulis header\n",
        "#     writer.writerow([\"Metric\", \"Type\", \"Score\"])\n",
        "\n",
        "#     # Tulis skor ROUGE\n",
        "#     for metric in ['rouge1', 'rouge2', 'rougeL']:\n",
        "#         for score_type in ['precision', 'recall', 'fmeasure']:\n",
        "#             writer.writerow([metric.upper(), score_type.capitalize(), evaluation_results['rouge'][metric][score_type]])\n",
        "\n",
        "#     # Tulis skor METEOR\n",
        "#     writer.writerow([\"METEOR\", \"Score\", evaluation_results['meteor']])\n",
        "\n",
        "# print(f\"Hasil evaluasi ROUGE dan METEOR telah disimpan ke: {rouge_meteor_log_path}\")"
      ],
      "metadata": {
        "id": "Z9OMXDqiEigE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# HITUNG DAN SIMPAN HASIL EVALUASI\n",
        "# -------------------------------\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "print(\"üìä Calculating ROUGE and METEOR scores...\")\n",
        "evaluation_results = compute_rouge_meteor(pred_answers, true_answers)\n",
        "\n",
        "print(\"\\n‚úÖ Hasil Evaluasi ROUGE dan METEOR pada Test Set:\")\n",
        "for metric, score_dict in evaluation_results[\"rouge\"].items():\n",
        "    print(f\"{metric.upper()}: P={score_dict['precision']:.4f}, R={score_dict['recall']:.4f}, F1={score_dict['fmeasure']:.4f}\")\n",
        "print(f\"METEOR Score: {evaluation_results['meteor']:.4f}\")\n",
        "\n",
        "# Simpan hasil evaluasi ke CSV\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "save_dir = f\"/content/drive/MyDrive/POLINDRA/SKRIPSI/chatbot_trial_finetuning/Komodo7B/{TOTAL_TRIAL_DATA}/EPOCH_{TOTAL_EPOCH_TRIAL}/\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "log_path = os.path.join(save_dir, f\"rouge_meteor_evaluation_log_{timestamp}.csv\")\n",
        "\n",
        "with open(log_path, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"Metric\", \"Type\", \"Score\"])\n",
        "    for metric in ['rouge1', 'rouge2', 'rougeL']:\n",
        "        for score_type in ['precision', 'recall', 'fmeasure']:\n",
        "            score_val = evaluation_results[\"rouge\"][metric][score_type]\n",
        "            writer.writerow([metric.upper(), score_type.capitalize(), round(score_val, 4)])\n",
        "    writer.writerow([\"METEOR\", \"F1\", round(evaluation_results[\"meteor\"], 4)])\n",
        "\n",
        "print(f\"üìÅ Hasil evaluasi disimpan di: {log_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-fECtVQFm1I",
        "outputId": "9b06d3b7-ca55-4eed-d7cc-57eb899a6e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Calculating ROUGE and METEOR scores...\n",
            "\n",
            "‚úÖ Hasil Evaluasi ROUGE dan METEOR pada Test Set:\n",
            "ROUGE1: P=0.1549, R=0.1214, F1=0.1276\n",
            "ROUGE2: P=0.0193, R=0.0133, F1=0.0148\n",
            "ROUGEL: P=0.1187, R=0.0909, F1=0.0963\n",
            "METEOR Score: 0.0986\n",
            "üìÅ Hasil evaluasi disimpan di: /content/drive/MyDrive/POLINDRA/SKRIPSI/chatbot_trial_finetuning/Komodo7B/10000/EPOCH_10/rouge_meteor_evaluation_log_20250702_075820.csv\n"
          ]
        }
      ]
    }
  ]
}